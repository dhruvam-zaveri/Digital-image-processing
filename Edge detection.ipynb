{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "opencv_txt = cv2.resize(cv2.imread('opencv_text.jpg'), (512,256))\n",
    "opencv_txt = cv2.bitwise_not(opencv_txt)\n",
    "cv2.imshow('OpenCV text image', opencv_txt)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge detection and Image gradients\n",
    "\n",
    "Edge : they can be defined as sudden changes in intesity level of image.\n",
    "\n",
    "<img src='https://miro.medium.com/max/1149/1*I_GeYmEhSEBWTbf_kgzrgQ.png' height='30%' width='30%'>\n",
    "\n",
    "## Types of edges\n",
    "Generally edges are of three types:\n",
    "\n",
    "1. Horizontal edges\n",
    "- Vertical Edges\n",
    "- Diagonal Edges\n",
    "\n",
    "## Edge detection algorithms\n",
    "\n",
    "### Sobel \n",
    "\n",
    "The Sobel edge detector is a gradient based method. It works with first order derivatives. It calculates the first derivatives of the image separately for the X and Y axes. The derivatives are only approximations (because the images are not continuous). To approximate them, the following kernels are used for convolution:\n",
    "<img src='https://aishack.in/static/img/tut/sobel-kernels1.jpg'>\n",
    "\n",
    "The kernel on the left approximates the derivative along the X axis. The one on the right is for the Y axis. Using this information, you can calculate the following:\n",
    "1. Magnitude or \"strength\" of the edge: $\\sqrt{G_x^2 + G_y^2}$<br>Approximate strength: |$G_x$| + |$G_y$|\n",
    "<br>The orientation of the edge: $\\arctan{\\frac{G_y}{G_x}}$\n",
    "<br><br>Refer following links for further details:\n",
    "<br><a href='https://docs.opencv.org/3.4/d2/d2c/tutorial_sobel_derivatives.html'>link</a>\n",
    "<br><a href=\"https://www.youtube.com/watch?v=uihBwtPIBxM\">watch video for Sobel operator</a>\n",
    "\n",
    "### cv2.Sobel(src, ddepth, dx, dy, ksize)\n",
    "\n",
    "- src : source image\n",
    "- ddepth : depth of the destination image\n",
    "- dx : order of the derivative x\n",
    "- dy : order of the derivative y\n",
    "- ksize : he size of the extended Sobel kernel; it must be 1, 3, 5, or 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sobel_x = cv2.Sobel(opencv_txt, cv2.CV_64F, 0, 1, ksize=7) \n",
    "sobel_y = cv2.Sobel(opencv_txt, cv2.CV_64F, 1, 0, ksize=7) \n",
    "sobel_xy = cv2.Sobel(opencv_txt, cv2.CV_64F, 1, 1, ksize=7) \n",
    "sobel_merge = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "\n",
    "cv2.imshow('Original image', opencv_txt)\n",
    "cv2.waitKey(0) \n",
    "cv2.imshow('Sobel X', sobel_x)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "cv2.imshow('Sobel Y', sobel_y)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "cv2.imshow('Sobel X Y', sobel_xy)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "cv2.imshow('Sobel Merged', sobel_merge)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian\n",
    "If the change in gradient is steep enough, you mark it as an edge pixel. Though these methods work well, there's one drawback - how do you decide what is a peak and what isn't? There has to be a certain threshold above which an edge is classified as a peak else it must be considered part of noise. Here's the next key idea: On the left (where the curve is rising), the slope is positive. On the right, the slope is negative. So there must exist a point where there is a zero crossing. That point is the edge's location. Edge detectors that are based on this idea are called Laplacian edge detectors\n",
    "<img src='https://aishack.in/static/img/tut/sample-edge-first-derivative.jpg'>\n",
    "$$\\text{1st order derivative}$$\n",
    "<img src='https://aishack.in/static/img/tut/sample-edge-second-derivative.jpg'>\n",
    "$$\\text{2nd order derivative}$$\n",
    "\n",
    "Unlike the Sobel edge detector, the Laplacian edge detector uses only one kernel. It calculates second order derivatives in a single pass. Here's the kernel used for it:\n",
    "<img src='https://aishack.in/static/img/tut/conv-laplacian.jpg'>\n",
    "\n",
    "You can use either one of these. Or if you want a better approximation, you can create a 5x5 kernel (it has a 24 at the center and everything else is -1). Simple stuff. One serious drawback though - because we're working with second order derivatives, the laplacian edge detector is extremely sensitive to noise. Usually, you'll want to reduce noise - maybe using the Gaussian blur.<br>For in-depth understanding of Laplacian edge detection refer<br>\n",
    "<a href='https://docs.opencv.org/3.4/d5/db5/tutorial_laplace_operator.html'>OpenCV doc</a><br>\n",
    "<a href='https://www.owlnet.rice.edu/~elec539/Projects97/morphjrks/laplacian.html'>this link.</a><br><br>\n",
    "\n",
    "### cv2.laplacian( src_gray, dst, ddepth, kernel_size, scale, delta)\n",
    "\n",
    "- src_gray: The input image.\n",
    "- dst: Destination (output) image\n",
    "- ddepth: Depth of the destination image. Since our input is CV_8U we define ddepth = CV_16S to avoid overflow\n",
    "- kernel_size: The kernel size of the Sobel operator to be applied internally. We use 3 in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = cv2.Laplacian(opencv_txt, cv2.CV_64F, ksize=5)\n",
    "\n",
    "cv2.imshow('Original image', opencv_txt)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('Laplacian edge detection', laplacian)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny \n",
    "\n",
    "refer following links :\n",
    "\n",
    "<a href='https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_canny/py_canny.html'>link 1</a><br>\n",
    "<a href='https://towardsdatascience.com/canny-edge-detection-step-by-step-in-python-computer-vision-b49c3a2d8123'>link 2</a><br>\n",
    "<a href='https://www.pyimagesearch.com/2015/04/06/zero-parameter-automatic-canny-edge-detection-with-python-and-opencv/'>link 3</a><br>\n",
    "<a href='https://www.youtube.com/watch?v=sRFM5IEqR2w'>youtube video</a>\n",
    "\n",
    "### cv2.Canny(image, edges, threshold1, threshold2)\n",
    "\n",
    "- image − A Mat object representing the source (input image) for this operation.\n",
    "- edges − A Mat object representing the destination (edges) for this operation.\n",
    "- threshold1 − A variable of the type double representing the first threshold for the hysteresis procedure.\n",
    "- threshold2 − A variable of the type double representing the second threshold for the hysteresis procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(opencv_txt, 20, 170)\n",
    "\n",
    "cv2.imshow('Original image', opencv_txt)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('Canny edge detector', canny)\n",
    "cv2.waitKey(0) \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
